---
layout: post-no-feature
title: RNNs Part Two
description: "Some more RNN attempts"
categories: articles
comments: true
published: true
date: 2014-04-30
---

Building on Jung-Hyung's
[encouraging results](http://jychung.wordpress.com/2014/04/05/how-should-we-shrink-alpha/),
I tried going smaller and training an RNN to overfit a single phone.

I implemented gradient clipping (my version rescales the gradient norm when it
exceeds a certain threshold) and tried increasing the depth of the
hidden-to-hidden transition, as suggested in
[Razvan's paper](http://arxiv.org/pdf/1312.6026v4.pdf).

The resulting model has the following properties:

* Input consists of the 240 previous acoustic samples
* Hidden state has 100 dimensions
* Input-to-hidden function is linear 
* Hidden-to-hidden transition is a 3-layer convolutional network (two
  convolutional rectified linear layers and a linear layer)
* Hidden non-linearity is the hyperbolic tangent
* Hidden-to-output function is linear

It was trained to predict the next acoustic sample given a ground truth of 240
previous samples on a single 'aa' phone for 250 epochs, yielding an MSE of
0.009.

Here are the audio files:

Original:
<audio src="{{ site.url }}/sounds/original_phone.wav" controls> </audio>

Ground-truth-based reconstruction:
<audio src="{{ site.url }}/sounds/prediction_phone.wav" controls> </audio>

Prediction-based reconstruction:
<audio src="{{ site.url }}/sounds/reconstruction_phone.wav" controls> </audio>

And here's a visual representation of the files (red is the original, blue is
using ground truth and green is the prediction-based reconstruction):

![Phone audio reconstruction]({{ site.url }}/images/phone_audio.png)

Unfortunately, as you can see (and hear), it's not on par yet with Jung-Hyung's
results, even with the extensions to the original model.
